{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SignSpeak_MNIST.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPoiFrLoWTDCxowZ5JRG2Ih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loki2124/SignSpeak/blob/main/experiments/SignSpeak_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4sOnBNTDgiJ",
        "outputId": "1f033c44-f249-4278-fbd3-a99c855bb9f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/SignSpeak/MNIST/data/archive.zip'"
      ],
      "metadata": {
        "id": "Znh7P8Ugqp6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245b76c8-4484-422a-81f7-35c25e0004d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/SignSpeak/MNIST/data/archive.zip\n",
            "  inflating: amer_sign2.png          \n",
            "  inflating: amer_sign3.png          \n",
            "  inflating: american_sign_language.PNG  \n",
            "  inflating: sign_mnist_test.csv     \n",
            "  inflating: sign_mnist_test/sign_mnist_test.csv  \n",
            "  inflating: sign_mnist_train.csv    \n",
            "  inflating: sign_mnist_train/sign_mnist_train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import cv2\n",
        "import time\n",
        "import copy"
      ],
      "metadata": {
        "id": "0AlKjLOHuxuW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('sign_mnist_train.csv')\n",
        "test = pd.read_csv('sign_mnist_test.csv')"
      ],
      "metadata": {
        "id": "Wi5uGP4kvQpA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "r5WHkbn43h35",
        "outputId": "073c3254-20a2-4fa9-a1f8-bf9f46684e35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     13     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcc15fd8-0e3e-47cf-bff1-df165085e422\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcc15fd8-0e3e-47cf-bff1-df165085e422')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcc15fd8-0e3e-47cf-bff1-df165085e422 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcc15fd8-0e3e-47cf-bff1-df165085e422');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train size:', len(train))\n",
        "print('Test size:', len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huqE6j688wDF",
        "outputId": "7936a6b3-5d19-46bb-e3bc-68d02f2deb4d"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 27455\n",
            "Test size: 7172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels = np.unique(np.array(train['label'].values))\n",
        "print(unique_labels)\n",
        "print(len(unique_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djTczXIHHuvF",
        "outputId": "27b4f8b2-9489-4d8e-9f69-5ba64108a207"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#updating the labels: decremented labels >= 10 to labels-1  \n",
        "train['label'] = np.where(train['label'] >= 10, train['label']-1, train['label'])\n",
        "test['label'] = np.where(test['label'] >= 10, test['label']-1, test['label'])\n"
      ],
      "metadata": {
        "id": "-w5foZ-vapLX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataset(Dataset):\n",
        "  def __init__(self, data, transform):\n",
        "\n",
        "    cols = data.columns\n",
        "    pixels = [i for i in cols if i != 'label']\n",
        "    self.pixels = data[pixels].values\n",
        "    self.data = np.array([np.reshape(i, (28,28)) for i in self.pixels])\n",
        "    self.labels = np.array(data['label'])\n",
        "\n",
        "    # label_binrizer = LabelBinarizer()\n",
        "    # self.labels = label_binrizer.fit_transform(self.labels)\n",
        "\n",
        "    self.transform=transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    \n",
        "    image = self.data[index]\n",
        "    image = image/255\n",
        "    image = torch.Tensor(image)\n",
        "    image = image.repeat(3,1,1)\n",
        "    image = self.transform(image)\n",
        "\n",
        "    targets= self.labels[index]\n",
        "    \n",
        "    return image, targets"
      ],
      "metadata": {
        "id": "LE39_I7a0ifL"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((32, 32)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomRotation(degrees=45),\n",
        "                transforms.ToTensor()])\n",
        "\n",
        "test_transform =transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((32, 32)),\n",
        "                transforms.ToTensor()])\n",
        "\n",
        "train_dataset = MNISTDataset(train,train_transform)\n",
        "test_dataset = MNISTDataset(test,test_transform)"
      ],
      "metadata": {
        "id": "vs4dof5i6bce"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vizualize batches"
      ],
      "metadata": {
        "id": "ZMFNknMYHIK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "id": "Zs5nNBzS63NM"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_images, batch_targets = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "zSKP27uN7W4k"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "\n",
        "# Get a batch of training data\n",
        "batch_images, batch_targets = next(iter(test_dataloader))\n",
        "\n",
        "# Make a grid from batch\n",
        "output = torchvision.utils.make_grid(batch_images)\n",
        "\n",
        "imshow(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "kM0flWDX7aSH",
        "outputId": "17e02d74-6eb8-469c-ebfb-3fbf5adb6ca2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29W4xs2Xke9q263/refW5zOBeBhAyGSCzDEGRYCA0pRihGMPVACJINh0YIzEuC2ImBmIoenAB5kJHIjgM4MgaWIjqQRMm0HBGCnYiZyBD8QEWkbdCyaNqcsUgOh2dmzpy+VVdV123loftb/dXfa+29q7rP6dPx/oFCVe3r2mv961vff1lrO+89SimllFJKuX1SuekClFJKKaWUspqUAF5KKaWUckulBPBSSimllFsqJYCXUkoppdxSKQG8lFJKKeWWSgngpZRSSim3VK4E4M65jznnvu6c+4Zz7jPXVahSSimllFLyxa2aB+6cqwL41wD+NIC3APwegJ/03v/B9RWvlFJKKaWUlNSucO73A/iG9/5NAHDOfQ7AJwAkAdw5V84aKqWUUkpZXh577/fsxqu4UF4A8G35/9b5tlJKKaWUUq5XvhnbeBUGXkicc68CePVp36eUUkop5d81uQqAfwfAB+T/w/NtC+K9fw3Aa0DpQimllFJKuU65CoD/HoAPOedewRlw/wSAP7vMBXq9Hh48eIB6vQ7n3KX9sW0xKXrcVeQ6F/1a9Vo877333sN7770X/lcqFdy7dw+7u7tLXy+r7pxzS5X1WbRDTFatz9FohLfeeguDwSBsa7fbuHv3LhqNRnieZb+zfsf+Fz0mS2LHF6mX69Lrd999F2+//Xa4nnMOL7zwAu7du1f42bLqLOu8Za7xvMtoNMIbb7yBg4ODQsevDODe+6lz7r8A8H8BqAL4Be/9v1zmGg8fPsQnP/lJbG9vwzmX2SEoqc7ytBorpeBZih/bp9vy9medN5/P8frrr+O3fuu3MJvNAAC1Wg0/+IM/iI9+9KOF68HeL6s+U2XPaye73Xu/0MFTErt3bFtendp7W3n77bfxy7/8y3jzzTfDtr29PXz84x/H7u4uKpVKeA7+1m/+rlarC8fp8+tH99k6sufF6iJWR3ntnaVrRXU4drxtjy9+8Yv4/Oc/j/F4DOBMJz/60Y/ix37sx0I92XKntsXqKnWulVi9LzO4FRlc7HVWwZ7U/d9++2387M/+LL785S8Xus6VfODe+38I4B+uen6z2cTe3h729vYuNegyIP6sAfw6wbvo8fyezWZYW1tbON45h42NDdy/fz/Kdoo8Q97gWUThY/e2HT0FAkVEn6UICKX2c9tkMkGj0VjYV6/Xsb29jb29vQWQtsBtAVz/x4A7BSp5gLMsmSn67LYtso5LXY/39d5jfX39Ujk2Nzfx8OFDVKvVS88KXAxauo/bYqCvx8We29ap1nvq+awUqe/U+cuSp9g1KpUKWq1WoesAzyCImScppdbv1DY9P+v6KSliPsYAMAWKRe6XdW7s+vrcRUf7IgyuyPHLnrvsccuwR21nrcdlBoGi7b3KJ3W+BW997mWJSuq31kuR53saknfd1IAV25e3ze7PK0dMT2J1VhS8ryp5urvMvW4UwPMaTr/t72Wun7d/GUDN2lb0/GVBXLdlDVh5yp7Ffpetq2XaIqtjFD1/FbCyx2vHKVL/KdBZBshT5UmBURH9zwKvVeolaz+laL0VuSd/FwHnZXQn65gUYBbpB09j0EvV5bL3ei4YuP29zIib2lZkX1EwijV+alvsvnof+zvFGGLlyupsRQa6oiCd2laUyaSut2znj+lDrC5TZbfltiBUpJ5SIK7b7LkpIE8dW6T9ivSN2POtChKpOlp2AI3dO/Usywx6qeOzji1StpiwXm09F5FlAfnWATiwPPOw5xbZlrrvdbpRskA5BSDLdISUgtv9qwxIPD/v/ln7VvFvx9wkRQbkmBulKDAVHexi4G194lkgnDUQ2OsW0fGsvsHfWeBS9NmzBmruzzs+T1J9Pq8e7fHqR8+7flZZli37qtfK0tdV6vG5AHBKUfAuAj6rdObUMfZ6RbfFylgExGPXuIrpau+TBxbL+lKznr1oO/A7BnCxY+31U/qRqu8iA13eM6VAeZlr5D1L1r6866p+W+BYVYetrAre9nfRvq/7igC0PSbllqQUtXKz4jOp868bvIHnAMCzgLdoo3IUXlYBi46WRQDWHpfyeRcF8dT1V2nkPEXPG/yyylYUCAFcygrw3mM2m2E2m2E+n2MymSxkR1Sr1ZCPbbMSlrmvfa6izMw+o35SDDx1jxTgxM6LtccyZY6BlgWYIgCSB2bLBoVT5c/q06m+z98pBs59sUFL99k+a+9nLa75fB7Sd3kO9RQATk9Pw35eTzNrsmQVknbjAA6kTSf9zttmf8f+F5UifurYOVnMpgiIF7n+VY4twlTsdYpIkXMt8PGY2WwWvieTSfjvvUe9Xg8perxGrGMXKXcWcBR5rhhIx/bpeXlgVRSoiwxWqzwfsLo1aa+x7MCS1VezBr0srIjdLwsrKpVK0DVrBeoxlnjM5/OF85xzqNVql/p0iqXn1dEyuHXjAF5kRM4D7BhYXmf5ruq+yLrWdV5/VcnqAFcJVvGbIMzfFHaA2WwG5xym0ymm0ynG4zGm0ymq1SqGwyEqlQrq9fqlHOxGoxHtYFet0yLgmQXm9jt1rL1X1rYi+7KeAYhblFdt46z+Zp+9KPDGrhM7PuvaAC4Bc6VSQa1WC3ronAvEwXuPyWSC+XyOarUa9LRWqy2QDuAMwOfzOabTKebzOWq1GqrVargfWfpsNgt6CiD0Ay3XVeXGARzIHmntcfZ31jFXKc91KXneta/7+s+LKNtuNBqhI6gZqQBO4B6Pxzg5OQnAzWu0Wq1wjWq1ilqthrW1NdTrddTrddRqy6tyFtvJY9lZ+/IY+FV0PXbNInGBlKTchEUl79xVBjDdnsfG7WQqfS51yRHAm83mAgkYj8cBuEkc6vV6OK5WqwV2zesSoHku9ZvH0B14enq6UC4FcLL41PMWlecCwCl5jDtrX96DF/Ex63FZrD5PYVMdKtZgsevH7rFMJ7tOCyR27yLKxg5nWbP1PdrtAAKgq4k6m80C06lWq6jX62g0GmG/ne0HXE/gNw9cY+fErmH3pbaljgcWGWVemew1FKiLbItJlk88tS0FxHmDW9Y1YucoOAJnIMpvfqwrzrrzptMpJpMJKpVKYM8pPFDiwRiOivrKef+Yj12vuYrc+ESeoiOtnlNkGyXPnxer1DzwzDtmWUZT5J7ctgw4Fzk27xit22V9o+xUZDFkz3o+fd40RdmJTk5OcHp6in6/D+89Go1GAG8Gje7cuYN2u43Nzc2wnSbyVdoiC2Rix8b+p9ZE4b48sNb9BACyPgAL7qNUXCAPLGJtG5OsurQDQOwZYmvK2PtnfewxOvhTr5rNJmq1WgDK6XSK0WiE2WyG0WiE8XiMTqeDtbW1oCfVajWw7+l0isFggOFwiFarhclkgmaziVarFeqYusvjaSnWajVsbGwEwK9UKpjP5xgOh+FeJCCp9tD6WUaeCwa+KlDnHV+ETWSxh9RxKcZcFDiKXD+1rajkMbRlr5XFHqxYhdTf1l+toKyR/ul0GgB8Pp+HgCY/zWYTvV4PANDpdC75FZVZLfvsRcHbHp/Sz6xj7XGx7epbnUwmAC7Aq0g75z1LjInH9tlrrTIw2mukBssUeNt7U6dIEpRxA1gY+NRis4OfZeDUR8veeazqKF0vOpAqA59Op5fqMIsQLaOvzwWAq2Q1dJFvey0gOythWddK3jaKNUuzzivKvpfpMKsAV0yy6lfvpb9pXjKwQ0UmG9Gg5Hw+Dx2KnZDsiIyGASHvffBPeu+xv7+P4XCIZrOJ9fX14A9ftq5WlRRoZzHI1Pl2O0EEuLBShsMhHj9+DO89ut0uGo0GWq0WOp3OAqBn6WXqOWL6avetQiJSg5vdn3V8rD6oN5YAxJ57PB5jMBjAOYd+v4/JZIJerxeuRyAnMJ+eni4w8Ol0ik6nExg0r00/92AwwOHhIWq1WtBBXpuD7nw+R7PZDGmxFsRj5S4iNw7gWSOw/V2U5TyvksXmrwrYsTq8KohnMVFbNmU8FAL3eDwOJiSVm0FJC+AMSBLoCeCnp6eYTqdhpTb6yGu1Gnq9XlgLvd1uF37mVepmGVa9DGjHzlNAms/nGAwGeOeddzCfz7GxsYF2u4319XU0m81L5ctya3C/3Z4iGtcB4npd+5xZg18KwFkOjYuoe06ZNQPj8/kcnU4HrVYrgLOycQXw6XQajplMJqjVapd0azKZYDQaod/vY39/H41GAzs7OwsAzvtrwJQEJtZWtw7AVVIdIfadt4+S50YpUmFZpmXRbavu0/8qqXLngUNRsfWc6vDKuNkB6M9mJ5pMJiFFcDKZLKRw2ee1QG4DoLVaLfgltQNobq6W76oDex5pSAF3rC6zdDd2T2WIfB7myg8GA8xmMzQaDUyn00vXTf1fxmVnQT1rW0yynq3ogKfsmgyY2SUsZypWZF12BFPqnnXD8F46F0EDkFbUrcX2ILFg2dk3mOVyenoaBp3UMy8juQDunPsFAD8K4F3v/UfOt20D+FUALwP4QwA/7r3fX6UAsdFW99nvlOLb84swhSxlt24B+zs1WMT+K9ClypFVXjtC53WM2L5lJNYGLAdweeYrGTJ9jUzF6nQ6AICTk5MAPGTim5ubaDQaaDQaqNfrmM1mqNfrAM582rxOs9kM9VOpVLC+vo67d++G67KzMW/cgriWM2tAjNWBZYBZDDF2jN4zC8TtfQlWNLcJAHSjjEYjHB4eAjgDs263u8Ao+Xx57a5lUl3VbUVAPPUssXqM9XUbhNW6bLfbgflWq9XAkHUGr80WIRgz/1rT/I6OjlCv17G1tRWepV6vw3uPVqsV9Gk0GgVwJqjbcjOHfDqdot/vo91uY21tLQSY2+12CMgT2E9PT9FsNrG5ublgka7q8isS8vxFAB8z2z4D4HXv/YcAvH7+f2lZFryz5Ko+z6uMgtdxz1THX6ZsWZ1kleOLnEthh5pMJsFUJOsm86bPkB+CtKZYaZ63+sKVhdGXaF0MdqDMGviz6ibrmFS9Zg2cRYA0NSDYYBtZ3mg0wsnJCUajUUhlW9b3HStjXl3ZbXk6tur9rS6oa40DSIoYxeqP1gx1kfWlx6kbRgdCmyJIUQY+HA4xGAzCtYEL64EsnvpPvbdttorkMnDv/e845142mz8B4E+d//4sgH8M4K9cqSQiRToZK1XNd/5no+g1dH9WZ9cy2G16fBari5lcy5hMWt68MhWVIoBjt6cGGIKnzXVlVJ7shZMhms0m6vV6OIaz02xQivep1+totVoLqYO81+npKU5OTgBcrDuhg0DWs+mzZHWc2EBWBMxjoJballXH6i5y58yTjLzdbgd/+Gg0wmAwCO/0nE6n4RxlpUWsjVi9LOOCSg1gWeQga+Bi21t3A8ul2SXMUrL1q5ZMu90OupJXFiUQ/AAXGS0kJWoVHR4eotVqYX9/P5RFmTjPGQ6HCzM419bW0G63AzGxabZ5sqoP/K73/rvnvx8BuLvidZKS6jDWLaEdmECuOZv8Vp+Wrr+R6vQ20V/vaUd9W64YG9LGuQpzWeW8Zdhiaj+30zSlWanmPQF8OBwCOHOFaFSeTIQgraxS65SdTtdCYb2S7QAI0X2WITZwaqfPqwO7vyjgpNqkCIBpWQheyj6dcyE/nhk4ZHnD4TC4VDj5hKDLT4w9xu6rYl0mep6CelE35TIgzue2wWxbBtUH6p7WnQ6EzNZhvRUtg51bEANw4IxIPHnyBK1WC0dHR2i32+h0Ouh2u6hUKiGTpd/vBwY+Go0W0kB5zrMC8CDee++cS7akc+5VAK8WvV6skSP3DJ2WrIwBHk0v0m89lx09NoNK/bw81+aAAhcsOwbwmubE61gLQBUtBgApX+OykleXedflM9l8bl3TRE1dBdzRaBTSsZQZaueynZEBupOTEwwGg+BuGY1GGI1GaLVaYb0KdhD6gHVQ4LNlWUpZoBv7X6QNso6JAWcK/FVPdKCk6OQeuqs0Z9k+exYopyRlBXJfESBPAXfsXnqsTQ3Uc3Sf1gNTV2Nl4nW1/3O7zQe39aPPSVeIugiZpjibzXB8fBzSOtvtNrz3Qfc1s4q6TiAna7ekMU9WBfB3nHP3vfffdc7dB/Bu6kDv/WsAXjuvjEstraCg//nbCiuflagRYAKGVoTNZJByLbDHWBYFAUEXtKESaLTZPG9Im+N0b7oEKpVKKLMTFhobdZXtrOLbjMkyJjGP14FKO5fW62w2C6lszWYzKPbjx4/hnEOn0wlmbK/XW/A5aic4OjrCZDLB+++/j6OjIxwdHWF/fx+np6fY39/HaDRCvV7HdDpFo9HAvXv30Ol0sL29jfX19QVz29ajrVt+Z4G4HbRig24MmFKDBbfHBm5r3VHHnHMhe0GzTQjcdKNQtwhiOjim2l37Q6oMWfWkzxeTWD3Ftln9Jmu2AzKlXq8HVxIHLgZ8Y8+l91JrjfsYxAQWYym8FutSwZrWz+npKY6Pj/HOO++gXq9jb28vtAN1nUCuPnC6ATkbtFqt4s6dO9HJWVmyKoB/AcCnAPzM+fdvrHgdAHHFT43S6grR0VcDZjyf7EVNIhVtTMvKtQGBRR92zE2i5WOAggOIKgXLm9XBLFu6CmirxAaJmMTuybIr61FGqCYn3Ssc5Og+IWBrXdl6YZCJgVBln7Ztms0m2u32Avu2YJOq22Xryu5LsfTU+QoKZNYxENO6YHxB19zQa6su6kf1WWNFsTrgNbQd9LgY49bzlpHUwBc7JubC5H4blFQ8SJUpNlhYYsJtsY/qPHHGBu5J3hib4fVZVjvbmFjBQSirXlJSJI3wV3AWsNx1zr0F4K/iDLh/zTn3aQDfBPDjS9118frR7bairXtCFVUbVc1KvU6WX1yZpjaMziaMAbiWTX/rUpL00WkDj8fjhewKO7DYTpNikE9DeE+1iFju4+NjOOdweHgYJiOQvZA58HmdcxgMBphOp3jnnXcwHo/R6/WwubmJZrOJ7e3tS/ncluFzunyj0Qjph7VaDaenp2g0GmE/A56rdICrSBaDtyybmSOquwpS6mLiNq4Dw3VhTk5O4L0PbiPvz9aIGY/HGA6HwUppNpvBItIJVqqnwMVSqRw0WQ62LctkB0BrNRYZ7LIAm6KWWWwwptCi1YA5B7kUg1WypwFeLaO1arjeCc+hTnMNlH6/j+Pj4/Cfdaz6q+4R9hf663WwzBq0sqRIFspPJnb9cOG75EisoayyKTOxbEwfXrMjaLao0qlLhPe2AK6MmUxaWTFw2dSKDQYEcgIbgOBCUUabx2Ri938aYpUawEIAkbPZKBp4YcCRYEvzfz6f4+DgICj6eDxGu90O61LQVNbnU586I/Snp6cB3Ol/1GyVVZaTzWJrV61nC+De++AGIUNTnWRgWDuwTqFn4Iv6zuUEGOAcj8dhmjgBXImABop5DVotvDYDbqx3C6Kq7zHSkWeFLMu8YwMEdaBer4eYF+uKBM7ey/ZLfQ49TskfB4bT01MAF7nko9EoDBwaROZsS2XdBG/mo+t6PqmB/9oZ+LMQ6zJQs88CuPXJWmatymqDGwRMYLGD6XXVj6jH2/SjFHjHzFGyRyqc9cHxGjEzj1KkYfUaqwAQz9HIu2b4EIDo4+92u2E9ZF3ljeyYbIMDIyc0EHSHwyE6nQ46nc6C+c/FqthGrHtmn7BuyZSYoqiWg7bPKhIzr1P1pf8tEKnbRAGcLEz91fa/6qS6o8juAITJT7SSbDlYRs075rOxrtUq5HU1+G6tUw66qzJw249s5k0scKmiJEz7mh2ktH9a3zdF+6i6SE5PTzGfz8OgyDLR701XCfPwOah0u12sra2h0+mEzDMb31M9vcp69sBzAOAWBLWSYyOmNoAFYW6jsuvMQMvQdaSncipLopJwYMhiBSy/9cHRhcIyqWmaxW6uWo9FwdveT815rjkCXEyFZxoUA4tra2tYW1tbWFiJsyu99yHQRPA6PDzEYDBAs9kM529ubmJra2shyEzTEwA2Nzcxn8+xvr6O0WiE4+Nj7O/vYzKZ4OjoKJSXloDNwLhKXapYINLvFENkuxMUONGDucAKWARQ7fDUCdY/iYBzDr1eL7Bsmv9k6vSrqq+Y2y0Dr1arAYh09ix1lX1IkwQ46KbqIFZnatFZUb3TyTop0fVPdHABEAVxjZEpuQMuXCuaWUI9Y8ymXq+HbKjhcBgmUB0fH+Po6CisdNhut7Gzs4O7d+9ia2sL3W53gZRatyktHmZRrUK6bhzAgbS/OzWaWuGIZs2hWLCN+yh2FNfjNWdU07NirEKVgv91YOEoraanBXD9VkXPYuZ5soxSWBOW99S6IQOnH1qnwquSaifTwA1N05OTk+A6IFPhxAd2Zh2cORDSVHXOXQp2XtXtEauPIq4Be6ytR1uHBBRLJgjQNhVOiYG1PC1QARezYvUcy1CBCx2zVqq1ImNBUl53GZ1UwNeBxD4Xf+ddW0kTXVI2iGv7tQK3umP1PLbPfD5fiF3pQMoPBw7m6POjE9Us/mhdaEaXtnlRuXEAty4TW/kpANcHVbBhAygTsetkWAXUxrVKoUqllW396DFrIWbC6QQFmk9WmQAsvAPSMrzrFt6Dfj47+1HZCRkkgzZU7K2trcCUW60WxuNx8P91u93AoDmD8O2330az2cT+/n4IbG5tbaHRaGBzcxO9Xm9h6dhut4vT09Pg+wSA4+PjBeaoMzevInkAndqn7IoDl77WC0Bg1Jy7QNePDR5ycKNuUb/UBcgBQNtJ157m9QAsuGF4T+q3BjE5QNJdRcuBgzfvl+deKlJvFA1e2tRBBXpeg8BJRszn56BPC5ADOwkHLY1KpYJ+v4+jo6MF96DGGobDYagbtmWlUllYBoK/G40GHj58iI2NDdy5cwe7u7tBf0k+dDkJtlGlUgmptbR4bxWAp5h2CgxjwKj+JG7LMpnYIZQFxK6trEdBNMbClaXrNVR4T17DTkZgGTmix3yBqzDw2ECnkhqglP0q66BC0t86n89DkJFgoeuYkFmTZRPQuH4y24kAzDrkOd1uN9RZo9HAaDQKU5PZgTgosDzXUW9ZoJNi5eqmy8ooUDDU9qZbQzNA1ELUe8esNw2Ya78gEKkLheXgtzJRWll0AdGFYvvdsmRCyx1z32k8y/ZPns/yagof+5a6Qlgf+kz8cKDSDBa6TvnhNWhVciKZXeNnOp2i3W5jY2MDm5ubwaVIfbfl1fRCDrAMHFOW0dcbZ+BZjFsVJuUXVyW3ed0KjFYhbEfnNey0We4nSyLL0xQ4BTrvL/zpZOq8BrC4kp8yINuhbWaGlqNIx1HzNCV8boK2BtB0dUF2EnYyXR9CJzeor18ZKf183W4XvV5vwTzt9/vB78gpx9vb26GuyELZ8brdLjY2NjAej3FwcBAsgqOjI0yn05Bex8EjqzMUqcfUYK379Hl18LKgzvplnZHF6bXokuLgZn3G1DVdxEoZHZm1prFym/YdvaeSleFwuAB66prRTKOi4G3rLfZt64d91T4L25OBRKbxzefz0C85CAIX2KJ1Tcvi4OBgATQ5IZAZJTqwal/23ofr93o9jMdj7OzsBAZO5k13DjNaOGBw0CBhopXKa8fcLVly4ww8BuD2Iaw/Tlk6K4LAadmiBXH1g2nn5mipYEyhsmlupw2aqb9MAU9zznkfPg87BhVMQT22SP+y4J0F4tpp6HsmkDOveDqdhs6iIEGlIwuu1Wo4OjrCbDbD7u7upU5JFn1ycoKNjQ2cnp7i4OAg3AdAyPc+PT3FvXv3Ql0xnQ1A8LXPZrPwFpTJZIJ+v48nT55gPB5jbW0N8/k8pB/adi4iMdBOATl/awaOBg85kBDYrRuKud68Hhk4A2fW4uMAqwBOPVIA47m6eh/rQu+n34xNjEajhbVoCI60ijR4mlePsTrV+8XcTtpP1RogqTk5OQkvUdjf3w+ZMQRBy+KZ6scApPce7733XtBdZkv1+/0wy5Lrhut6PMy8YbyA78F88OABvvd7vxfdbhebm5thWV+WnXXK6+tAz8loamndKgaexbxTx1gmYf8DCK4JPZ/gz281ca2yEYAsW9HfsU4QMy+1XNavrC4Kvf8ybDuvftXUjj0DPxz0CDKaE8861c6mDI1uFTW1ebz6++nTVveRBo40UKQWlgIhGapegy4cmw4Xa4NlJNYGtt2Vgesndr4lI6xDe20AGI1GlybMWAsp5pNOkZQsi04ZvP7XHH/7ujB7vWXF1lusrpW0sa2pa/xo8JbbtP9aVwozaqhHPEYtYWXdms9NAlar1cLyDRsbG+h2uwuvXVNCyb7OMmjd6mC/LHgDzwGAU2IAruzZgm/MNwZcpD9x9TE1M2mKkU1qwEhzyWM+9VTHo5JYS0LP5W8AQXnoV9MOqktKplZiS4F6FthbgFAmreBO5qGvoOLzVCqVAIpcYJ8KSkbN2YJc4pO53L1eD7VaDcPhEDs7O8FUdc6F+9EtUK1WA8NiXZB5O3fm3+XaEr1eL3SU999/P6QmjsfjUJdZHSK2r6i1o8zb+vpt8JBlV/+yTgbRcvD1XZVKBScnJ1EioCRG4xatVmvBbWSBOVZ2tZQ48NHyabVaIbeZrrDYq8BSvn69lzJiYNEC1HWHKHw+6hT763w+x+HhIQ4PD7G/v4+DgwNMp9Ng+VBXqTfOuaDXw+EQx8fHAaQPDw/R6XSwsbGB+XyO4+NjDIfDhdeecbnX3d1d7O3thbIBFymLa2tr2NvbCxaY9xczrvnyDbJ/Xpsv4KDloBi3jNw4gFvAs7+tGyTGti3zZgOq71szPdjIPFcbXpmTZmJomdQlQ4mBty2bnq+sQtmkZbnLShGzNsa6CIQM1DBLQtmRDiwEDdYPAVkXtFefIQGdueFqmrLMysLJrGx76v3JCOlbZDC1Wq2u1BlidVgExGN+buqRJQM2oGUZOI+zVh1w4dPV+1tATZUtxrpV7zQLRgcjkiFus24pLV9ePenzsW5iZbQESCfS0NrSj6awqkEBSxkAACAASURBVC5Qf9XVpO+lZKBSF5siuLMtCbScdazPogNnr9cLdWGtUvvyEmBx7SC19JeVG/eBU2Igbb+By+4KFfWV0k+n5r6mdMXYE4NmdlYUFYRKRpBSsy9W3pR5au/JvFGuskagjHXMLCkC3grGVBwyYDJfAjiA0HlZJgaM2GEAXJrk8+TJk8DiuDqhcxcBSLI5grSdaGVNWrar+jbZVnxtFU3rfr+P+fzshQeMU+hgs0pHidWrDrzUGX6rTuhbiAgefBatU+t2UqDgYMSUPgBhOYL19XXcuXMHjUYjpGHqSn6qR9bloxlHuo0DA6+hKa1XqTvtszqA6L0o1uLV3GwFQQ5gdB0ROEkcLMawHZRE0N/N67Xbbezt7aHdbuOFF15At9vF7u4utra2ou4wsnxtK51mz7VsYnGklKutqNw4Awcus20bqNQROctUo7AzUUnIcthw7PDKPmj6MqVHfVNUGJ7vnAtrc8Tur24HDSyx4bTjM8jHoFvshb2p57TbiwK4fjSFqt/v4+DgINQRQVJNXe/9JQBnBL9areLJkyfY2NjA+vo6Njc3g5sEQFjMiuDO+3I5TR1UtNPyPpbZtloteO/DgkOTyQTHx8eYTCbY3NwMwTg1r5cB8JjbQQcQWgLUGfUPs+2YhcA1NAjgtk41EKkZLLwO2ePh4SGcu3jby8bGBl566SV0u13cu3cP7XY7ACLvE9MBBXAFIn1u7ZfWlbhM/alu6r0sgKsok9X8detH1iwlZb7A5ZRSuunYDqx/XVyO8xC2t7fR6/Xw4osvhuwpzlJl2XSGqurgbDYLLhO6IzlIsI01tdbq2DJy4wCuIG2zUfJcEioxV4UNYqpoJ9T1upVtWDNYmbGyJGU2Knp8DMA5aOgEmjx/4lXFApEFJc2SsdlAsWNprVCZmRHinAvrG2snpeK2Wq3wEtnZbIZWq4VOp4N2ux1SDunDVoaqOmIHJO7Xjq6W0Cr1aY+xVlRsxqkeG8uwsNeM6bzVK+/9QvomGbm2kQ0YZ5XfWoVFQJnH2eOzgMcOCqnjLDnjNUnGSDS0L6seWpeZ1r26CRmk13uxvvgiBuZ0Ux81RZFl5beyfpZRXTWaN67xNasvti8WlRt3oWiA0bogLIjzHP0GLs+o1Jc9aFRZO5/3Ppj4XMOgWq0Gdm5dLVQmOxNTgTfGtjWoZc1VZVoxBY9ZHMs2sB6r91cfOwcZ5mEzuAZcWB8WtJmqxxmWDP5861vfwjvvvINXXnkF9+/fD4v68JzJZBIWvm82myGXt9vtBnP15ZdfxsOHDwM7peXDVE121phPXjMRGMzM8gNn1VusLXhPTjJSBq7nsL6oX3wbOdkj61Yzf7S91cWmgUnWxXQ6DW8tYkaFmuZ28ItZi5bkWEmRHt2XxchVZ6x7RJm/uiPVOvDeh/RSBiKpB7SEWUcaU+I9GXTlsg0AQvCYqYDOOWxubgYLhtkkzCihC1EJAtuM7hiybbaJ+r4nk4u30jMFM+ZCielcEblxBh5jH0UZuFUcbVw7CFihsrAiddlSO+VYXS0a7LHbYoEgMns7w5FlsM9iGUaM8SxbvzFmo7/pH9ZypsqjrFdzaFnGk5MTnJycYGdnJ6T2sUNq/jhnU3IA1/cI8qP3Z6fR1DktEz8xHYg9u63/oqIAoezbBpyVPauOKBvk89n4j8ZbFDQ1I0ddTDpNnveOuUa0XMtYt/a5iupkjFWmrA91yelxtDg4Icle37oErYVoma7VZ83FpuuP1qGSLFtfyr41XVCZt00f1PvGrINbB+BWabPANwXoei2ybWXfscqjKEviehw6i4qTebTTWratimPNI4I5r5FnRmq5rgvE7XWs8umkJx6nYKgr5xEUyKjJeDj5oVar4fDwEP1+H9/5znfw1a9+FWtra3jxxRextbUVUtJqtRoePHiAwWCAo6MjHB4eotlshs5D0Ff9YHbMyclJmHXJ1f04042d0T6HrYvUf63/mJ4QQMmkOFDHBkiyZp1pZ015/SgAsz3UuiAh4NvVOZHn6OgIb7zxBtbX19Fut7G1tYXd3d2F4F7qGa9D8nQ6BeApILfnEtRp8XAA4zm0yGq1GmazWYgn0TdOHa3Vauh2u3j48CEmkwn29vawvr6Ovb09vPTSSwHASeRsIJn3Y1vRXcL4hmZvEcQ184TWAv3p+jb6IvWYkiJv5PkAgL+LszfPewCvee//pnNuG8CvAngZwB8C+HHv/f4yN1cwiQG49WHHTD79VgBX1ww7hAVBNhCj+Z1OJ3QEfU2SdT0UMcF5ffu8qXqInRsD8aINHLNUFMQtm2W9WiuBQR/GCVhfvB4BhsG1x48fhzf2fO1rX8PGxga2trYCgHPNE+fOgpudTie4ILgsrfp52X4sBzNl6OphHroyNMv8irgHbN3beuYAxqCoZnpooIzf3EYLJQ/ALfsm+HvvF+IIdHNRx/mijI2NDWxvb2M8HqPVaoWMCevysM+pepFVN8pgY0w4ppcxBk5rL2tgtfVOnaNbg6BNN95sNgvATr+1DqwcCDqdTpjl+z3f8z24c+cO1tbWsL29vbAmSVYcSgFcXSXUQX7r/AY+H5+BlibJim2LZUC8CAOfAvjL3vt/6pxbA/AV59wXAfwFAK9773/GOfcZAJ8B8FcK3/lcstwmdn9RsYqTqhQNQHASCXBhtsVALRWIss+kZeG22Dkx1mEB1/7Ok7zjWJZYkFYDYWTh9FESJNUdoMAyn8+D+6NaraLf78M5h+Pj4/Cb91M2yw6nFpC1EuwCQpwQk5rlpoNtkTrJqyt1mdiAc2zgyJM8wAMuwIJZFbpUhLJ8Nd/JBNlmrAMFkhSxUKIQqwc9V63CZVljXt+M9RmyaO99cE0qA+fAoKt9sp2YPaLWHRee0iBlDLitVWQXvCLLtotcUR+Bi5VF6SZUv/pVLaEir1T7LoDvnv8+ds59DcALAD6Bs3dlAsBnAfxjLAnglomkwFxZtiqNdS0oIFmfGM9X4Vof/X4/zOTb2dkJLIeAXsS8iQ06un0ZAFYpel6RQc76/9i5m81mAEvgDDg6nc5CAIbBQXYIdg7Oytza2kKn0wlsczQa4dGjR9jf38fDhw9RrVbDCxzotmKH5LU055wdgjEJ+yorvtCBZeQyocxaoJuD97AZNayPWH1bUKlUFl81RiCw6X7Kxou2Ce/JQUv1lqlndGHxOXgc1zzhxJWjoyNUq9WQd6yBMpZFnysPPPLIRVY9FrmHDrZZYEZdta/iY0CQJGw+ny+k53EeQKfTWbA8K5VKyDLRWaCxwYT1rW5ZDVjqG+p1IhwJRr1ex8bGBprNJnZ3d3Hnzp2FF3Grlbgs+waW9IE7514G8H0AfhfA3XNwB4BHOHOxxM55FcCrqWvGwE73Ja6Z9AsXYd7WjNXV4ZSdqmkcU9gU047dy/7OEnuvVcHfXismGrBU/361Wl0wdVlfMTZHMPHeh3RAnaDDumWwkx0SQJilqYFhbR91gelHA3h2hq3GIGLsLq8u7TmxGEiKfcfOj7ntinZWupGU4Og9VI+1rvS42P1iZVWAt3oXY9ur6qQtg/2d2s/+qMFznQDEuIFmJ8UsJbJhDgA2jqHPZ12OloFbxh2LKSmhUCszS2eKSmEAd871APx9AH/Je39kGtI756Kt6b1/DcBr59e4dEyWi6SIKae/laUoAGllqRISvE9PT8Pi7vSr5pmGsfLmDTi23LbDZJ1bRNlTndR2Zns876ETNcg4CbrK0Pmt9+LxOzs7aLfb2N/fD5N7NOCpfmOavDbi75wLjIfAz0FAOw39jww20w3DNSZ0sSILolmuAgIgAZu+SzJafXNQrN5tx9cBUsEllh0Rs5AUoDnLkGIntRAgCF5WP6zO2G9rSWYNeLHBK1afsWtpvRVxS7I+CL76fNQFBjMZR2HAXCdH8cM6yis742q0AHUJ5H6/H1brVEuRqbLtdhvtdhvb29vodDoLLypRS+0qUgjAnXN1nIH3L3nvf/188zvOufve++865+4DeHfVQiwDXvZ4C1jWDI0pqR5L18BgMIBzbmF1s2VGxTyXSawjFGXnqQHAHpMa0bUeYx9lNgQKBho561Kj6eqO4LW1Q9A/yXcCqivKBvNig7emF8YW0CfL0RUdtWPyY1MibX2lhGXSdEEOCFmZJxbEbRqjTXlLufj4zf28jroKrGhZU5PCsvRIdSTGuq9iCWada3UwJdQjuk/YBtQFulLIzu0MWermMsCpzFuXRFB3CTOg7Ft3ONhznZRerxcyZPJcRstIkSwUB+DnAXzNe//XZdcXAHwKwM+cf//GqoVQ0NHOqAptlTvPfRHbT9anPkF+bGCCQTYLWFnPEOsAWp7UQFRkoMoTWhIxls1n1HqghWLTIJUlEpi1znh+ir1yP1dyq1QqC8qrSxyo+a+Ap9uVfab+83pkx/R9x1LBigyG3Me0RGXzKbZo28oyTQ0OxwCWzxwjGuoiYDvQdaQzW3UGa2rwKgIaWqYYiKee+SqSZ/Fq2bQ+OUuTOsF+mzUDtsjgbd0mdglb/a+BdNZJo9EIeq+6b+MkV5UiDPxPAvjzAP6Fc+6fn2/7b3EG3L/mnPs0gG8C+PFVChBjjvxNJgzE88BjroHYsQAujXoKGBqgGw6HGAwGaLVaYUGsGEvMYtR5bHtVSZl73i8uu6lArceQpVCpmcKkk20AhGAQBzymbtlAWuxDwGm322Eq/d7eHnZ2dkLUX4FFfYZ2beeUz9GyHfoWdRo+A41WT2x9ZHVm5u0ycKmmuK3/GOHQAY2MkHVrBwTWK+tf70GwAhBcKGSD9Xo95BVvb29jd3cXa2trIR8+prvLylWYd1YfiVkeeYMqgAXXEICg04y5qOtLYxbLlJv6Rxce3+fKNwExeM60Qb5ph4Nsp9PB7u4uut0utre3g8+d7XhdUiQL5Z8ASNXqD1+1ADFQsqN9jN3ElCPVgex99JvHaECTJpCeGytHjI1kMZWix8fulSeWgccGNXWVaDqamrH6Wz/sCFrHGqixZecAQVNSmafWZ6ytUoODDh6x/HX92OtYSW3XZ7cpg1mAn2ov2x6xuo7phR0Ubdm0nsnCaYHQXRB7zizLyTLvrOeyz7iMpCzmIuAdqw8ACzpqATuLeWfphg0OW0JhA5csB3Vfg5ZW969LbnQmpiozJcaw9b+yZgsgPEazHlQ5abYTNLmfJmmlUsHh4WEIPKyvr1/qtFkd1YJybF/euUXrTWU+n2N/fx/f+ta3Lim11g2ZQb1eD2u/aB42fYmaWqUgHwNTndgAYGEtcZqNOnHBug7UpxvL904xcfWNO3fxLkmWk6zIAqHWx+np6SX3GK0Hzphj0Mmu50HJGgjsQGhN+pgri/VK9qfABGBhfRS2597eHra3t7G9vR3SOekvXsb9l7UvZXXocak6yDqGZdRBrahoBgldKbbcdhDMEtaV6hhTVmmZ0weuM4Cp89VqNbDt3d1d7O7uhqys6wxcqtz4WigxBm5NdYoFDqucqvyxKfTW96335nlcGrLX62WW2Yo1oy3o57lVsti57k8p4mAwwMHBQZTl8Zo0Mzkle21t7dKSAAo2AALA0JUSA3B9Pk0f1KwNnU6uDElXhou1r/V7q8tFZ9jarIv5fL6w/nusjlU/tE1iueSxNTGyxAJXLGslxcJZfpZP9/EZeS59rRpnIFjY/hED0xTp0G0xi9juW0Ziz7uKKFnRtrdlVVKYEqvXNlCufm8lEJZIcMo/20SD309DbhzAY5JnOlvwYMNQ4TU7QVk6G5VArkpOJnlycoJGoxFejksFyTMpl1XorONjHSWvvgaDQVjGldfQLAamVq6trQVw4ltEWAdalzorNdUGrD/nLl70akGR7cGX7MYyWGynibFszUzhh9cgWPP1VfQP800rej8FjidPnoRZjpRarRZ8yvSjp5hTDBgs4LLMnCXJ5UZ5jgaLta14LbU0ObBqsI4Dca/XC26UZYKXMctx2W15YJzaH+vny0jsXP2t9VbkGsy00rfoMC1Q13TX1FbqDwPJ29vb2NzcxMbGxsLU/Kclzx2A24bIY2QK5GwAAoDuA7AAxuwc+hsADg8PMZ1Osb6+HjqKSpY75TpBPHZcVp0dHR3h0aNH4b8yO9ZJtVoNs8I4SHG/HTR0eVZ1odg6BS5ykRWY6AJghxgOh1GAjzFsu6aEAroCO+uG93LubC0W9btrm6lF4pzDu+++G948RKnVamFBf/ovU3VuBzZeV3WEz8IgGM1vrWcAgelzoFLw5jddXrSmOAhvbW2FmYWchZiyPGJyHSCede2s/1qXy4rWfQzMY8TEiuofdY3txfRivpSBL2bQNXjG4/FCAP3u3bu4c+dOCKZfd9aJlRsH8NgIqkxPlZhKbUE9ti3G0GOSYhEpnx7LaI8pCtj2+Nj97T77OyZ8fv1PMFFXA90bag7autJ7WtdKzDRV95T6dVkmNTVZDn7bjpflNrEDtj4rn4sAyTeuaL1bl8VwOIz6wDUGkKrrmEWi7Rzzp9JyUEKhrioVzWhQ/SbjI/hrjvqyud+6/7oA2147b3uMOReRlM7Ya+h+HVz1XOqVzW6yhMFag2pF0YWlLype1qe/itz4crI0MZW5aYWq2WyBXINolrHothQIKhsjCDHxntNs81wn1yFF/I9a3pgQeLSs9niCAVOg9vf3A5Bx/RE7iUlzavV8BVj1RTJvXIObXP4VQHhDPes21kn4n6mRXLNGF8nnfenXJ7s9Pj5O1jH92Hyeo6MjjEajS3XERYdigXI7MHnvL/naFRy4TsvR0RGOj4+DC4UAzNX0WLcKELaex+Mxjo+PUalUsL6+Hpbg5cJMur6GHWCzdOe6ADt1bb2/BVHWKeu+iPDZ1MpTchD78PrUO7XW2SZ8GQPX25lOpzg+Pg6zL8nAB4PBQuxna2sLH/7wh9HtdgP7ftquE8qNA7g1g3REtH7PGIArSPMYHY21omNiG1dn8V3X6BkbBGJsPtVRioC47SQqZMdkhuqmoNmo9anX1Dxlnf3GstuOYlMO5/N58H8zz1vLmeUes6xHy6nMmccDF3GQ2LOw/GSufI+hrUfuV+ZGibE+rTu7n+a4rhPNemOaImMDNvVNgY3/me3gnFuYuETXiaYYWl1I6Y4C9dMAcXt/6spVrm3rWQO+1EPWqbahzfTR9XSYvZa1PKxakmwXvtGLS8Vyspo+89OSGwdwsi0dVck8uL6A+rStu0Q7ja4TbDumNZ+ZgkXQZvT+zp07Cy/kZTn5/TSZeJ5c5f4KxLPZLExIaDab4ZVTKZOP9aWgpp1CQZ31y4kU9C3OZmdrNfPFD3RR2Nls7CCxgKZ2nhhIA4tZGhxMOKGDQUlOcd7f38ebb76Jg4ODhTrWTm3rXAmEdelo3SiL5jmaV854gNYhy6uDLQcUXpPPtru7i729Pdy7dw9bW1vJ7JMiAKJgqlJ0W4rha1/T/qexqDzrICbWfRazXpV8aD9mW2ggkmy73++H/4PBIGybTCbo9/sYDAYL8Za9vT1sbGzg3r17wWrPW1/luuVGAZxuEgVwXZiGwQKOgNZc1RHXe78QIFIT2/pwqehMu+p2u+EdjVtbW2E68nUxj2chWh9WtNOwc49GIxwfH6Ner+P4+DgwCb6swboOCOBq9nIfU6j0Q+Ckwk+nU3Q6HZycnIRJDtVqNQredi0U/ShoKoDrfZ1zCxNbmMvNN/4wc+PRo0f40pe+dKke7dRoHcD1/pbtK3mgWc5nIoB778PbY2JAxgFIB0nOKNUXjNy5cwcvvfQS7t+/j+3t7YVFtiyoxXQiBnqrShaA60CqoGqPuSqQ27LYwUJdtKxLsm2+2anf7wf3CV13unDVYDAIddtoNLC3txfeNrW2thZdJ+dpy3PBwDUTgB1Xv7UjsROoQtD3W6/XA/iTrVi/J4GFq5XR7GHOZupVWc8SyK15edV7x0xWggsZB1kxsxxi/lM1R4uY5vY4gjlByAYpLXhbsLbAzWvrTDdl2wQ1+iTpJ+bkCr6vVMUy6ZhfWwmEfux19Dzg4kUhyqjt3AS9PuswlqOvmTax4GURnbASA/XUQGDdLjHROrAWm2XR1n3EY2P1zbbRyVpq5agrSQcHJR90aam7xK5xoqmCOghzmQ0NXCpe/DsD4JPJBIeHhwAuTF41TXVpV/qcWFkEXzIs51xYm4DBL2XousgRGVmv1wuskyk/eVNerVvlaclV2b8FWH5omTCQWalU8OjRI/T7/VA3KbOUnYHukhho6Lk2C2Q8HuPw8HDhNWPKtGlBMSBJF5oF+fF4DAChrTY3N7G1tRXebUqXGAGOOsO8XLoyhsPhpTRBdaFYXzuw6GOPgUusLqi7DFjO5/PAqjlrlYBkBygFbH3jfLfbXXiv4rMCkLx+YYXAbYPj+pwEWw64akkRaG1sjN/UBV6bWTnsy6kBst/vL7xVngxc3zLPoLHOFeh2u3jppZfQ7Xbx4osv4t69ewvLFzxL8AaeAxeKvlFEWZn6ESlsIHZQujo2NjZCo/N6FgDJvLhKni5UxIWG7KQdlRT7SEmMvRc9J3XMKgoS81dSkQlUg8EgpBamwEjBoQjjih2rDJyuGpsmqEAdA0l1LbDNyYZarRY2NjbCTFN2LLatstVKpbIQbLLPoSzc7sti4Lbu1LWlk6Pm88W3sFsLQ+td3QEMsOrLkmNtUhRoi5IEa8HZ75jYNlNRn75en79prZCQ6QCngzoBXN2jHBToplIdIrYMh8MwSYc+cGXl6mIh2eBAura2hrW1tYXlYW8CvIEbBvDT01O89957GAwGoYLY4ACCcpJtNBoNbG1thfU1CMidTif4cAlKug4GgKDw1Wo1rP2hfkOdKk1JAWpMebMUOnZcUUldL++cvH1U5tPTUzx58gSj0Sj48lg3eqwClA0wWndXCoyY7sd21Vmeaq7qNXVA528uNsYXUd+/fx8PHjwIL6e2C1ApO1XfvgUV+3yxgcz6u/UYm5mibiEFMwUfpkeS/bFsBGuy1+n07O0z29vb6PV62N3dxc7ODnq9XjL75LqtxBQZSMnJyQkeP34MAAt1oPWgrFjz4tVq0wlhBHLVP3Xj0LrSgS92L07U0aQJm42iaYp8Y/36+jru3r0bZr/eFPOm3DiAv//++xgMBoEdsYGr1eqCX5qR9nv37oUAlfo92VDayYELhdaULVY6O3aMlVgXxPMC4ldVFMuIT09PcXh4GKahMzPFslMFqRRrTgE462Q2mwV/O9kS61+D19ZtYoGRjGhtbQ3r6+u4c+cOHjx4EAZzsi8FaMuQYxks3B9jjLpPAShrn/rztc5VR2kx0mQniOkAxOM5aK2vry/MvrQrRdq2vi7dsf0i79jhcIj9/f3gKrJ6QVDVzCLbTpqVpECu2/Qc69azgy2/1a9trSjbts65EADvdrvY3d0N5MFOwHrWcuMuFH1xKyvDex/8sfRpdTqdsC4zMxjsWr82VVAVOisSbqWICyW2z5qWqePtuVlgb7ctY/Lm7aNCTyZnb5vnRBjvPdbW1hbKrswzC7i1k1jGpfWhKXGa+hYDWnt9Dr50o6Vmv1mwtr5lAoIVdXvofwV3lsnWkbqmlM2pCU/WbdfXGI/HlzJ99Pr08RM87NKxMVF9uQoj13YpKnTPeX+RQaNM2AJ4TG8sgGtmj4J6nrWkFhXvabfps6qbrlKpYDAY4Pj4GEdHR3j8+HG4Ly0gkpFnLUXeyNMC8DsAmufHf957/1edc68A+ByAHQBfAfDnvffj9JUuy3Q6xdHR0cI7Bs/vGd7iTB/3nTt30Gq1sLm5Gd5MTcnyXZtnWaZ4S4uWfxmFvw5zVweumKRYmALKe++9F3KMt7e3FywizRAZjUah88T8kxZ0CWgUDqTMHqFPONYB7fRmBgQbjQZ2dnZw584d7OzsYH19/RLgsgw8z74uj+vexOqKPmqNGaiZbQFcmR6Bi+lnrC+eyxmZ+/v7ePLkCcbjcZitSrfefD6/9Fad9fV1fPCDH8TGxgb29vZC6lrK1XdVncqTGHvVfdaFoiAdA3AFWt1HK0Z1jfqoMzEtWFufudaJWmjaN7QPM25Ci47B9WazibW1NbzyyivY29tDp9PB1tbWM5k6b6UIAz8F8EPe+747ezfmP3HO/SMA/zWAv+G9/5xz7m8D+DSAn1vm5qzwWB4xK07T2zRtSkdJIHsmYureMVkGTGP3WfbcGLDqNmX1q4iel7IKqNz0ybKj2A5qfdH63x5rmbTdzgCTBplsvShwqltDJ+hQLzR/2p5PgNClAoDFtchTdZdXHls/6vfWwUddRAzM6SQma2VYgkJLVJcpjU3XjulJngX4tESDjLHsHZtVkgJwu7RACsDVdWVJRQzAbT2zLgjE1M1qtYrRaBRwaH9/H9PpFHt7eyGjjcTiWUuRN/J4AP3zv/XzjwfwQwD+7Pn2zwL477ACgOtI7L0PGQTMKNje3sbGxkbI5dXzLNAp2N1UUOG6xIK3BmRWlazOPZvN0O+fNXOj0cBwOARwwZaVQeoEK8u8Yx+blsfMEY1DABfTnFUvFPwYvNzc3Aypg5ubm+Gt9loOXTeFM+j0DfYA0O/3FwA9VWcKAroWi/WhamDt6OgofHOiiK65wZmw3MbnZ6yGmVZcL6XZbOLhw4d48cUXQwqtDVwuC95PW9h+qrfKwGODICU1YFoWr4TC6pqCe8rdxd8qSiQ5SLIt9/f3cXx8HN4XMJlMcPfuXWxubmbOZn5aUvSt9FWcuUk+COBvAXgDwIH3nr3hLQAvJM59FcCrqWtbdkezmn7vXq+3MOmCymCV1jJaBfH/v4A5kH6hcFGJDW5sg+FwiNlshvX19eCPVSaiAKUsSAdh2yEtK1KGZTMO1Iqy5/JjF8wnG6Wo24SgyecigLMu6dpI1bktB6+rvlh9Zh6js/u4DCkzowjgmn9MAGFd60SdRqOBzc1N9Ho97O3tYW9vLxAcC+Cxtr5JtDsBCQAADcJJREFUIXhqOS0w629KlvUW+1irUPPEY5aNPTc2gLAtZrOzeRN8XeHR0RGOjo7Q6XRw9+7dMJeE93jWLLwQgHvvZwD+qHNuE8A/APBHit7Ae/8agNcAwDm3oFGsJA1iMRWMuZa6MmCscmJ+31WAOxaIzDr2OlwwseNTLEqZQ5HrZx1j9/HZFaBGo9GlWW2pDmSfI9Y5uJ0dwroI9FgL2mqhMSOJzJvuE9vmysYI3PzWzpmqa3XPaUaJTuu3gTkFcJ2URH84XVNkdgRhtR7b7XYAaE5OYtbDzs7OpRUH9ZmtXEdspci1UvfXjC8L0NblGesHRUDb6mFMt2P4YPXW9n9bBhW1PG96kFwqC8V7f+Cc+20AfwLApnOuds7CHwL4zioFIEiwQTqdDu7du4f19XXs7e1hd3c3ZKMAl9fo0MaJMbllpajfeZXOkfKZZ12LygosvmZrFUkBN78JSicnJyEbhTMAU53HXs8ybwVfjXfweM395Xm6UqIuYAWcLUf7gQ98AOvr69jY2AhzAOzzETAHg0EIEJI500WR8oFbcFCLg1kjBOlYAI0zTvlNVw3dCVw9kGloaqorgO/s7KDVaoX1TjqdTsjTTw36KTKTpQdFJaanWS7LWq0WlmZQa0UJgWWt2h9S8Yas+AvLZD9aF3qPPKzggKv34zl57rdnIUWyUPYATM7Buw3gTwP4awB+G8AncZaJ8ikAv7HszWMVzUYnu2LQUiWlMM9SVukEttwpU1H3WVNTsx+uW/QeOgHFSlbniF0zxqz0Wrrd+jT1eGafEORsEM+WKcXo6XvPsnb03hZI1JWkwTKW2a6wqPEBZjaQSdO6VABvtVpotVph7RZdNoIutDz9y2oPay0VuU7M0soTDs7eX7xAvKi1nNKZPGZeVK5yrAbROZnwKqTxKlKEgd8H8NlzP3gFwK9573/TOfcHAD7nnPsfAPwzAD+/7M3ZkcjAAYS3bJNh0cfJ/dqQWYwgdb+UZCl0iu0UuZa9rn7baLyyORsEVJcA13m5Don5nXV6PV0emuvKPHybKsjMEgqfj0zbWku6QiJdD/QN61oo3vsAdNvb23j48OGluIi64nTZVuDirTj0S7OcsQFqPp+HFel0ANDXbVlmz6nY6oOl2+T4+BjD4TCUsV6v48GDB9jZ2cHa2lpIP2PWFf3e9Xo9BO4ZxFT3kG1D/c5r7+s2+2P3dc6F1/ZxEAMuMp5U73SRNJWsgZT1bQlODMxj/VH3pQaBmL62Wi3s7u5iY2MDH/zgB/GRj3wkzBJ/LtMIvfdfBfB9ke1vAvj+qxZAOx9Ndr5PjpN2YrPMzsuwcB1uWxbY7fWy7lVU+VMKpNsUwDX1iYxFMzHI7OjmKCrLdFgLWKkAG91ZugAZj4tNpEnVi3W5aIDUuk44gHQ6HWxubi74gjU+oqtVcpsy5vF4HAafVDtrHWv7KEDrC2+5ZrQOZgxYEvAZmK9WqyGPe2trC3fv3g3PpmudqI9c61Otr5T7MK+Nr0tirisVWtNsI5sJkgJ+HpNi3amAZFEWHmP3WcBvPQRc2mN3dxf3798P7fW8MvCnKlo5mmWiHdr6SfW82LWuIllmdWp/1nViiqiMczabLbDN0WgUgFx9qgrgT548KVSOLP9nnsuDQMVjtQ00HmH9gQRTHZQJqtbdwftphoe6OpTBcx1vvriAMxZpISjDtUyWYK46pWtsqCgDV31U8GabcALU0dFRSC+0bhVO5CHb5jfTYzmTj8+ggWPqigVqdUXEQLyIWMKj7Z9HgIqSAroZqAM60KcAN/bfutJiEgP7lKxCapRA6Do0MRfvs5QbBXAL3tymjEzXhwDiAPS02EcKhK9ybixXmIEuLmqkKW+avUDAf/ToUW45Yp2+SFmBxRmQ7NA2o4CMSl0pBCBdzwO4YMV2gGW5lNVq8JIdnssHE/D0De7sXLw23W2Mo/BYlpdLN3ByhgXw6XQagrh20pi23Wg0CuD8+PHjsLodl4flh8cwHZCs+/79++j1emEGqQ5WMRaqOh6LPRQBbwvWMdEB4qogzqV8ASwsHZxivSnGnQXiWcdque0glaofK7wWJ4z1ej08fPgQu7u7IRPqJuW5WAtFA0AnJyd4//33wxKzXKc7lUIY+52SVczHq4C3PR/AQjoaTe/j42MMBoPwwlQCjQKbsnL7Il7vfVgDPVUntrNYINCyNRqN0Abdbnch20LLoUE9Di4EMS7TyTbW/Gi6E/gyZb6Zh5kb+vqqyeTs7fL9fh/OOTx+/Bjf/va3F9wgzJnWZ93f30e/38fBwUFYbVHrmfexU+nH4zHeffddAIgC+PHxMUajEQ4ODnBwcBAm5Gh2itY3ByOuM1OpVPDOO+/AORfeDAQsxgtieqRtZtu2SD+I6XDK2iy6X5/TWoXeexweHuKtt94Ki9bpixIUaG0aJsmKWp2qf7qYFV2OOlEsdn1139gBIZXJwnMBBE/AcDjEwcEBnHP45je/eWk9+avKt7/9bQwGg8LHu1VAbVVxJg9cZ+SxHIy+cwH+Iq8oelq+p1XrJo/tKiBoQMb7i0WeshSMK9ipMKhnZRVzkaYiF4yikmp59D9wEZzS7BFNIdSORBeHLj6m/n+7UhwDp7VaLaTSWTZoU9F0OjuZNgcS9d0fHh4urNPCNFbqpfXzqovEDqwEEBVu55rlXE+agWC6o/QeWW22al9Y1foseuyjR4/w1ltvLcRM7t+/j7t37y4QNWXHWcyb19E61e8Y87ZkK/Y79nxZBI3baFlyHRRaVN1ut3A9FZHRaISvf/3r2N/ft7u+4r3/43bjjQJ4KaWUUkophSQK4M9+9ZVSSimllFKuRUoAL6WUUkq5pVICeCmllFLKLZVnnYXyGMDJ+fdtll3c7me47eUHbv8z3PbyA7f/GW5T+V+KbXymQUwAcM59OeaMv01y25/htpcfuP3PcNvLD9z+Z7jt5QdKF0oppZRSyq2VEsBLKaWUUm6p3ASAv3YD97xuue3PcNvLD9z+Z7jt5Qdu/zPc9vI/ex94KaWUUkop1yOlC6WUUkop5ZbKMwVw59zHnHNfd859wzn3mWd571XEOfcB59xvO+f+wDn3L51zf/F8+7Zz7ovOuX9z/r1102XNEudc1Tn3z5xzv3n+/xXn3O+et8OvOucaede4SXHObTrnPu+c+1fOua855/7ELWyD/+pch37fOfcrzrnW89wOzrlfcM6965z7fdkWrXN3Jv/L+XN81Tn3x26u5BeSeIb/8VyPvuqc+wfu7D2/3PdT58/wdefcf3wzpV5OnhmAu7M3+vwtAD8C4MMAftI59+Fndf8VZQrgL3vvPwzgBwD85+dl/gyA1733HwLw+vn/51n+IoCvyf+/BuBveO8/CGAfwKdvpFTF5W8C+D+9938EwH+As2e5NW3gnHsBwH8J4I977z8CoArgJ/B8t8MvAviY2Zaq8x8B8KHzz6sAfu4ZlTFPfhGXn+GLAD7ivf/3AfxrAD8FAOf9+icA/Hvn5/yv55j1XMuzZODfD+Ab3vs3vfdjnL1L8xPP8P5Li/f+u977f3r++xhnwPECzsr92fPDPgvgx26mhPninHsI4D8B8HfO/zsAPwTg8+eHPO/l3wDwH+L8lX3e+7H3/gC3qA3OpQag7ZyrAegA+C6e43bw3v8OgCdmc6rOPwHg7/oz+RLOXnh+/9mUNC2xZ/De/5Y/exE7AHwJZy9kB86e4XPe+1Pv/b8F8A1cwxvHnrY8SwB/AcC35f9b59tuhTjnXsbZq+V+F8Bd7/13z3c9AnD3hopVRP5nAP8NAK5zugPgQJT4eW+HVwC8B+B/O3cD/R3nXBe3qA28998B8D8B+BbOgPsQwFdwu9oBSNf5be3b/xmAf3T++1Y+QxnELCDOuR6Avw/gL3nvj3SfP0vjeS5TeZxzPwrgXe/9V266LFeQGoA/BuDnvPffh7OlGBbcJc9zGwDAua/4EzgbjB4A6OKyaX+r5Hmv8zxxzv00zlykv3TTZbmKPEsA/w6AD8j/h+fbnmtxztVxBt6/5L3/9fPN79BEPP9+96bKlyN/EsCfcc79Ic5cVj+EM3/y5rkpDzz/7fAWgLe89797/v/zOAP029IGAPAfAfi33vv3vPcTAL+Os7a5Te0ApOv8VvVt59xfAPCjAP6cv8ijvlXPQHmWAP57AD50Hnlv4Cxg8IVneP+l5dxf/PMAvua9/+uy6wsAPnX++1MAfuNZl62IeO9/ynv/0Hv/Ms7q+//x3v85AL8N4JPnhz235QcA7/0jAN92zn3v+aYfBvAHuCVtcC7fAvADzrnOuU7xGW5NO5xLqs6/AOA/Pc9G+QEAh+Jqea7EOfcxnLkU/4z3Xt9d9gUAP+GcazrnXsFZQPb/vYkyLiVZrya67g+Aj+Ms8vsGgJ9+lvdesbw/iDMz8asA/vn55+M48yO/DuDfAPi/AWzfdFkLPMufAvCb57+/B2fK+Q0Afw9A86bLl1P2Pwrgy+ft8H8A2LptbQDgvwfwrwD8PoD/HUDzeW4HAL+CM3/9BGdW0KdTdQ7A4SzD7A0A/wJn2TbP6zN8A2e+bvbnvy3H//T5M3wdwI/cdPmLfMqZmKWUUkopt1TKIGYppZRSyi2VEsBLKaWUUm6plABeSimllHJLpQTwUkoppZRbKiWAl1JKKaXcUikBvJRSSinllkoJ4KWUUkopt1RKAC+llFJKuaXy/wG/8sZybJgqOQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_images[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3GqqxlV_H-K",
        "outputId": "b1b136d1-095c-46fc-a3c7-6c2333aaa3df"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model : MobilenetV2"
      ],
      "metadata": {
        "id": "7whVHID2Bf4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n"
      ],
      "metadata": {
        "id": "_xa2ElgWBmDd"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(model, num_classes, feature_extract, use_pretrained=True):\n",
        "    input_size = 0\n",
        "\n",
        "    set_parameter_requires_grad(model, feature_extract)\n",
        "    num_ftrs = model.classifier[1].in_features\n",
        "    print('Pretrained model has 1000 classes')\n",
        "    print('changing the classifier layer to predict {} labels...'.format(num_classes))\n",
        "    model.classifier[1] = torch.nn.Linear(num_ftrs, num_classes)\n",
        "    input_size = 32\n",
        "\n",
        "    return model, input_size\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "Xf5LcgzfLkb4"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model_ft, input_size = initialize_model(mobilenet_v2, num_classes = 24, feature_extract = True, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWmafY80MMN4",
        "outputId": "125d6fdd-4949-4db5-9b22-6912e8244344"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained model has 1000 classes\n",
            "changing the classifier layer to predict 24 labels...\n",
            "MobileNetV2(\n",
            "  (features): Sequential(\n",
            "    (0): ConvNormActivation(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (16): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (17): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (18): ConvNormActivation(\n",
            "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Linear(in_features=1280, out_features=24, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: CNN"
      ],
      "metadata": {
        "id": "ICHr7NJ2f5ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, num_classes=24):\n",
        "        super().__init__()\n",
        "\n",
        "        #Conv group 1\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size= (3,3)),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU()\n",
        "                                   )\n",
        "        \n",
        "        #Max Pooling\n",
        "        self.maxpool_1 = nn.MaxPool2d(2)\n",
        "\n",
        "        #Conv group 2\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size= (3,3)),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Dropout2d(0.1)\n",
        "                                   )\n",
        "        \n",
        "        #Max Pooling\n",
        "        self.maxpool_2 = nn.MaxPool2d(2)\n",
        "\n",
        "        #Conv group 2\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64, 64, kernel_size= (3,3)),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU()\n",
        "                                   )\n",
        "        \n",
        "        #Max Pooling\n",
        "        self.maxpool_3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.flatten = nn.Flatten()       \n",
        "        self.cls_layer = nn.Sequential(nn.Linear(256, 128),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Dropout(0.3),\n",
        "                                       nn.Linear(128, num_classes)\n",
        "                                       )  \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x = self.conv1(x)\n",
        "      x = self.maxpool_1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.maxpool_2(x)\n",
        "      x = self.conv3(x)\n",
        "      x = self.maxpool_3(x)\n",
        "      x = self.flatten(x)\n",
        "      x = self.cls_layer(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "LcVzgcEcf8sP"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloaders"
      ],
      "metadata": {
        "id": "-xpUkkVNOwY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((32, 32)),\n",
        "                transforms.RandomHorizontalFlip(p=0.1),\n",
        "                transforms.RandomRotation(degrees=10),\n",
        "                transforms.ToTensor()]),\n",
        "    'val': transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((32, 32)),\n",
        "                transforms.ToTensor()]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "raw_data = {'train': train, 'val': test}\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: MNISTDataset(raw_data[x], data_transforms[x]) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: DataLoader(image_datasets[x], batch_size= BATCH_SIZE, \n",
        "                                  shuffle=True) for x in ['train', 'val']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us6vj1XbOy1T",
        "outputId": "f10050da-8c60-43e5-e678-0477f8bdcb4d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer"
      ],
      "metadata": {
        "id": "1h0OFRgqQfDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model to GPU\n",
        "model = Network()\n",
        "model = model.to(device)\n",
        "\n",
        "############ For pretrained models #################\n",
        "# feature_extract = True\n",
        "# params_to_update = model_ft.parameters()\n",
        "# print(\"Params to learn:\")\n",
        "# if feature_extract:\n",
        "#     params_to_update = []\n",
        "#     for name,param in model_ft.named_parameters():\n",
        "#         if param.requires_grad == True:\n",
        "#             params_to_update.append(param)\n",
        "#             print(\"\\t\",name)\n",
        "# else:\n",
        "#     for name,param in model_ft.named_parameters():\n",
        "#         if param.requires_grad == True:\n",
        "#             print(\"\\t\",name)\n",
        "####################################################\n",
        "\n",
        "# optimizer_ft = optim.Adam(params_to_update, lr=0.001, weight_decay=1e-3)\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
        "scheduler  = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'max', factor = 0.5, patience= 2, threshold= 0.01, verbose = True)"
      ],
      "metadata": {
        "id": "kZ-gmxJFQhCr"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "buhsYavkKZG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.float().to(device)\n",
        "                labels = labels.long().to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val':\n",
        "              scheduler.step(epoch_acc)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "metadata": {
        "id": "zV_0oysmB5K9"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs= 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQUTLnBkRLvf",
        "outputId": "95655a9b-15fb-4d18-a05c-b7f7a14d1683"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.1199 Acc: 0.6733\n",
            "val Loss: 0.3980 Acc: 0.9014\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.2290 Acc: 0.9397\n",
            "val Loss: 0.2363 Acc: 0.9396\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1125 Acc: 0.9717\n",
            "val Loss: 0.1731 Acc: 0.9491\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.0761 Acc: 0.9816\n",
            "val Loss: 0.0830 Acc: 0.9731\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.0581 Acc: 0.9863\n",
            "val Loss: 0.0759 Acc: 0.9792\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0488 Acc: 0.9887\n",
            "val Loss: 0.0834 Acc: 0.9778\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0411 Acc: 0.9915\n",
            "val Loss: 0.0629 Acc: 0.9834\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0359 Acc: 0.9923\n",
            "val Loss: 0.0679 Acc: 0.9789\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0373 Acc: 0.9915\n",
            "val Loss: 0.0822 Acc: 0.9741\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0346 Acc: 0.9920\n",
            "val Loss: 0.1649 Acc: 0.9490\n",
            "Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0217 Acc: 0.9958\n",
            "val Loss: 0.0677 Acc: 0.9720\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0178 Acc: 0.9973\n",
            "val Loss: 0.0604 Acc: 0.9817\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0174 Acc: 0.9974\n",
            "val Loss: 0.0592 Acc: 0.9798\n",
            "Epoch    13: reducing learning rate of group 0 to 2.5000e-04.\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0141 Acc: 0.9984\n",
            "val Loss: 0.0540 Acc: 0.9791\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0133 Acc: 0.9987\n",
            "val Loss: 0.0499 Acc: 0.9863\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0138 Acc: 0.9987\n",
            "val Loss: 0.0558 Acc: 0.9784\n",
            "Epoch    16: reducing learning rate of group 0 to 1.2500e-04.\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0131 Acc: 0.9987\n",
            "val Loss: 0.0513 Acc: 0.9822\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0123 Acc: 0.9993\n",
            "val Loss: 0.0539 Acc: 0.9816\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0138 Acc: 0.9984\n",
            "val Loss: 0.0511 Acc: 0.9784\n",
            "Epoch    19: reducing learning rate of group 0 to 6.2500e-05.\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0127 Acc: 0.9987\n",
            "val Loss: 0.0483 Acc: 0.9801\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0118 Acc: 0.9989\n",
            "val Loss: 0.0490 Acc: 0.9798\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0114 Acc: 0.9994\n",
            "val Loss: 0.0499 Acc: 0.9826\n",
            "Epoch    22: reducing learning rate of group 0 to 3.1250e-05.\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0115 Acc: 0.9993\n",
            "val Loss: 0.0486 Acc: 0.9819\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0113 Acc: 0.9990\n",
            "val Loss: 0.0492 Acc: 0.9816\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0114 Acc: 0.9991\n",
            "val Loss: 0.0483 Acc: 0.9815\n",
            "Epoch    25: reducing learning rate of group 0 to 1.5625e-05.\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0118 Acc: 0.9990\n",
            "val Loss: 0.0504 Acc: 0.9795\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0109 Acc: 0.9993\n",
            "val Loss: 0.0501 Acc: 0.9808\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0115 Acc: 0.9993\n",
            "val Loss: 0.0485 Acc: 0.9806\n",
            "Epoch    28: reducing learning rate of group 0 to 7.8125e-06.\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0118 Acc: 0.9991\n",
            "val Loss: 0.0480 Acc: 0.9796\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0115 Acc: 0.9992\n",
            "val Loss: 0.0474 Acc: 0.9812\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0110 Acc: 0.9993\n",
            "val Loss: 0.0478 Acc: 0.9809\n",
            "Epoch    31: reducing learning rate of group 0 to 3.9063e-06.\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0109 Acc: 0.9995\n",
            "val Loss: 0.0486 Acc: 0.9809\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0116 Acc: 0.9992\n",
            "val Loss: 0.0491 Acc: 0.9801\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0112 Acc: 0.9993\n",
            "val Loss: 0.0486 Acc: 0.9812\n",
            "Epoch    34: reducing learning rate of group 0 to 1.9531e-06.\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0117 Acc: 0.9990\n",
            "val Loss: 0.0474 Acc: 0.9813\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0113 Acc: 0.9992\n",
            "val Loss: 0.0476 Acc: 0.9813\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0110 Acc: 0.9993\n",
            "val Loss: 0.0474 Acc: 0.9812\n",
            "Epoch    37: reducing learning rate of group 0 to 9.7656e-07.\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0109 Acc: 0.9993\n",
            "val Loss: 0.0480 Acc: 0.9813\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0111 Acc: 0.9994\n",
            "val Loss: 0.0472 Acc: 0.9816\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0113 Acc: 0.9991\n",
            "val Loss: 0.0471 Acc: 0.9815\n",
            "Epoch    40: reducing learning rate of group 0 to 4.8828e-07.\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0116 Acc: 0.9989\n",
            "val Loss: 0.0479 Acc: 0.9815\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0108 Acc: 0.9994\n",
            "val Loss: 0.0481 Acc: 0.9819\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0111 Acc: 0.9992\n",
            "val Loss: 0.0472 Acc: 0.9817\n",
            "Epoch    43: reducing learning rate of group 0 to 2.4414e-07.\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0108 Acc: 0.9992\n",
            "val Loss: 0.0477 Acc: 0.9815\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0114 Acc: 0.9992\n",
            "val Loss: 0.0481 Acc: 0.9815\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0109 Acc: 0.9994\n",
            "val Loss: 0.0479 Acc: 0.9813\n",
            "Epoch    46: reducing learning rate of group 0 to 1.2207e-07.\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0109 Acc: 0.9992\n",
            "val Loss: 0.0469 Acc: 0.9817\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0108 Acc: 0.9995\n",
            "val Loss: 0.0476 Acc: 0.9813\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0109 Acc: 0.9996\n",
            "val Loss: 0.0487 Acc: 0.9812\n",
            "Epoch    49: reducing learning rate of group 0 to 6.1035e-08.\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0106 Acc: 0.9995\n",
            "val Loss: 0.0484 Acc: 0.9806\n",
            "\n",
            "Training complete in 9m 58s\n",
            "Best val Acc: 0.986336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/SignSpeak/MNIST/Models/MNIST_CNN')"
      ],
      "metadata": {
        "id": "yue9V8Z99KrS"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZNbGFfEU9zIH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}